{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc45785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imread\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, ZeroPadding2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e5187be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet101V2 as ResNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet121 as DenseNet\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 as inceptionNet\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7 as EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb650628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Model():\n",
    "    input_ = Input(shape = (640,640,3))\n",
    "    \n",
    "    Res = ResNet(include_top=False, weights='imagenet', input_tensor=input_, pooling='average',classifier_activation='softmax')\n",
    "    Inception = inceptionNet(include_top = False, weights = 'imagenet', input_tensor = input_, pooling = 'average', classifier_activation = 'softmax')\n",
    "    \n",
    "    Inception_mid_In = Inception.get_layer('mixed7').output\n",
    "    Inception_mid_pad = ZeroPadding2D(padding = (1,1))(Inception_mid_In)\n",
    "    \n",
    "    Res_mid_In = Res.get_layer('conv4_block7_out').output\n",
    "    \n",
    "    mid_concatenation = tensorflow.keras.layers.Concatenate(axis = -1)([Res_mid_In, Inception_mid_pad])\n",
    "    \n",
    "    ENet = EfficientNet(include_top = False, weights = 'imagenet', input_tensor = mid_concatenation, pooling = 'average', classifier_activation = 'softmax')\n",
    "    ENet_Out_flatten = Flatten()(ENet.output)\n",
    "    ENet_Out_Dense = Dense(3, activation = 'sigmoid')(ENet_Out_flatten)\n",
    "    \n",
    "    Res_Out_flatten = Flatten()(Res.output)\n",
    "    Res_Out_Dense = Dense(3, activation = 'sigmoid')(Res_Out_flatten)\n",
    "    \n",
    "    Inception_Out_flatten = Flatten()(Inception.output)\n",
    "    Inception_Out_Dense = Dense(3, activation = 'sigmoid')(Inception_Out_flatten)\n",
    "    concatenation_out = tensorflow.keras.layers.Concatenate(axis = -1)([Res_Out_Dense, Inception_Out_Dense, ENet_Out_Dense])\n",
    "    \n",
    "    output = Dense(3, activation='sigmoid', name='output')(concatenation_out)\n",
    "    model = Model(input_, output)\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c1394b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"tf.math.truediv_11\" (type TFOpLambda).\n\nDimensions must be equal, but are 1792 and 3 for '{{node tf.math.truediv_11/truediv}} = RealDiv[T=DT_FLOAT](Placeholder, tf.math.truediv_11/truediv/y)' with input shapes: [?,40,40,1792], [3].\n\nCall arguments received by layer \"tf.math.truediv_11\" (type TFOpLambda):\n  • x=tf.Tensor(shape=(None, 40, 40, 1792), dtype=float32)\n  • y=tf.Tensor(shape=(3,), dtype=float32)\n  • name=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m      3\u001b[0m plot_model(model, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36mcreate_Model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m Res_mid_In \u001b[38;5;241m=\u001b[39m Res\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv4_block7_out\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moutput\n\u001b[0;32m     12\u001b[0m mid_concatenation \u001b[38;5;241m=\u001b[39m tensorflow\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConcatenate(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)([Res_mid_In, Inception_mid_pad])\n\u001b[1;32m---> 14\u001b[0m ENet \u001b[38;5;241m=\u001b[39m \u001b[43mEfficientNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmid_concatenation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maverage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m ENet_Out_flatten \u001b[38;5;241m=\u001b[39m Flatten()(ENet\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     16\u001b[0m ENet_Out_Dense \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m3\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)(ENet_Out_flatten)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\applications\\efficientnet.py:730\u001b[0m, in \u001b[0;36mEfficientNetB7\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.applications.efficientnet.EfficientNetB7\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    721\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.applications.EfficientNetB7\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mEfficientNetB7\u001b[39m(include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    728\u001b[0m                    classifier_activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    729\u001b[0m                    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 730\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m EfficientNet(\n\u001b[0;32m    731\u001b[0m       \u001b[38;5;241m2.0\u001b[39m,\n\u001b[0;32m    732\u001b[0m       \u001b[38;5;241m3.1\u001b[39m,\n\u001b[0;32m    733\u001b[0m       \u001b[38;5;241m600\u001b[39m,\n\u001b[0;32m    734\u001b[0m       \u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m    735\u001b[0m       model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficientnetb7\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    736\u001b[0m       include_top\u001b[38;5;241m=\u001b[39minclude_top,\n\u001b[0;32m    737\u001b[0m       weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[0;32m    738\u001b[0m       input_tensor\u001b[38;5;241m=\u001b[39minput_tensor,\n\u001b[0;32m    739\u001b[0m       input_shape\u001b[38;5;241m=\u001b[39minput_shape,\n\u001b[0;32m    740\u001b[0m       pooling\u001b[38;5;241m=\u001b[39mpooling,\n\u001b[0;32m    741\u001b[0m       classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m    742\u001b[0m       classifier_activation\u001b[38;5;241m=\u001b[39mclassifier_activation,\n\u001b[0;32m    743\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\applications\\efficientnet.py:334\u001b[0m, in \u001b[0;36mEfficientNet\u001b[1;34m(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    326\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mNormalization(axis\u001b[38;5;241m=\u001b[39mbn_axis)(x)\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    328\u001b[0m   \u001b[38;5;66;03m# Note that the normaliztion layer uses square value of STDDEV as the\u001b[39;00m\n\u001b[0;32m    329\u001b[0m   \u001b[38;5;66;03m# variance for the layer: result = (input - mean) / sqrt(var)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    332\u001b[0m   \u001b[38;5;66;03m# original implementation.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m   \u001b[38;5;66;03m# See https://github.com/tensorflow/tensorflow/issues/49930 for more details\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMAGENET_STDDEV_RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mZeroPadding2D(\n\u001b[0;32m    337\u001b[0m     padding\u001b[38;5;241m=\u001b[39mimagenet_utils\u001b[38;5;241m.\u001b[39mcorrect_pad(x, \u001b[38;5;241m3\u001b[39m),\n\u001b[0;32m    338\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstem_conv_pad\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m    339\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\n\u001b[0;32m    340\u001b[0m     round_filters(\u001b[38;5;241m32\u001b[39m),\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m     kernel_initializer\u001b[38;5;241m=\u001b[39mCONV_KERNEL_INITIALIZER,\n\u001b[0;32m    346\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstem_conv\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py:107\u001b[0m, in \u001b[0;36mKerasOpDispatcher.handle\u001b[1;34m(self, op, args, kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"Handle the specified operation with the specified arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(x, keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor)\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten([args, kwargs])):\n\u001b[1;32m--> 107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m TFOpLambda(op)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNOT_SUPPORTED\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"tf.math.truediv_11\" (type TFOpLambda).\n\nDimensions must be equal, but are 1792 and 3 for '{{node tf.math.truediv_11/truediv}} = RealDiv[T=DT_FLOAT](Placeholder, tf.math.truediv_11/truediv/y)' with input shapes: [?,40,40,1792], [3].\n\nCall arguments received by layer \"tf.math.truediv_11\" (type TFOpLambda):\n  • x=tf.Tensor(shape=(None, 40, 40, 1792), dtype=float32)\n  • y=tf.Tensor(shape=(3,), dtype=float32)\n  • name=None"
     ]
    }
   ],
   "source": [
    "model = create_Model()\n",
    "model.summary()\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808e16d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
